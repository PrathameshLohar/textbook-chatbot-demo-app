{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q streamlit pyngrok transformers bitsandbytes accelerate peft"
      ],
      "metadata": {
        "id": "Z39iX_QdSdQa"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YOnXgFirRjgu",
        "outputId": "82b536f3-d5bc-45fe-bea3-a27e058c5e04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "import torch\n",
        "\n",
        "st.set_page_config(page_title=\"LLaMA 2 Textbook Chatbot\")\n",
        "\n",
        "@st.cache_resource\n",
        "def load_model():\n",
        "    bnb_config = BitsAndBytesConfig(\n",
        "        load_in_4bit=True,\n",
        "        bnb_4bit_compute_dtype=torch.float16,\n",
        "        bnb_4bit_quant_type=\"nf4\",\n",
        "        bnb_4bit_use_double_quant=True,\n",
        "    )\n",
        "\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        \"Prathamesh25/Llama-2-7b-chatbot-textbook\",\n",
        "        device_map=\"auto\",\n",
        "        quantization_config=bnb_config,\n",
        "        torch_dtype=torch.float16,\n",
        "    )\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"Prathamesh25/Llama-2-7b-chatbot-textbook\")\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "    tokenizer.padding_side = \"right\"\n",
        "    return model, tokenizer\n",
        "\n",
        "model, tokenizer = load_model()\n",
        "\n",
        "st.title(\"ðŸ“˜ LLaMA 2 Textbook QA Bot\")\n",
        "\n",
        "user_input = st.text_area(\"Ask a question from your textbook:\", height=100)\n",
        "\n",
        "if st.button(\"Get Answer\") and user_input:\n",
        "    prompt = f\"<s>[INST] {user_input} [/INST]\"\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(**inputs, max_new_tokens=150)\n",
        "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    st.markdown(\"### Answer:\")\n",
        "    st.write(response.split(\"[/INST]\")[-1].strip())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from pyngrok import ngrok\n",
        "# !streamlit run app.py &> logs.txt &\n",
        "# public_url = ngrok.connect(port=8501)\n",
        "# print(f\"Streamlit app available at: {public_url}\")"
      ],
      "metadata": {
        "id": "0I72oLn4SRHZ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64 -O cloudflared\n",
        "!chmod +x cloudflared"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rP5ZIB1BTJju",
        "outputId": "054c3e39-2218-49be-a950-3d02d90aefc2"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-06-28 16:20:46--  https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64\n",
            "Resolving github.com (github.com)... 140.82.113.3\n",
            "Connecting to github.com (github.com)|140.82.113.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github.com/cloudflare/cloudflared/releases/download/2025.6.1/cloudflared-linux-amd64 [following]\n",
            "--2025-06-28 16:20:46--  https://github.com/cloudflare/cloudflared/releases/download/2025.6.1/cloudflared-linux-amd64\n",
            "Reusing existing connection to github.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/106867604/015db4d3-519c-4e00-a1a6-289640709684?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250628%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250628T162046Z&X-Amz-Expires=1800&X-Amz-Signature=9b046ece4f67a8f67b27bf8d165c4e644c197140303a9da2da78b50d12dd206c&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dcloudflared-linux-amd64&response-content-type=application%2Foctet-stream [following]\n",
            "--2025-06-28 16:20:46--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/106867604/015db4d3-519c-4e00-a1a6-289640709684?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250628%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250628T162046Z&X-Amz-Expires=1800&X-Amz-Signature=9b046ece4f67a8f67b27bf8d165c4e644c197140303a9da2da78b50d12dd206c&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dcloudflared-linux-amd64&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.108.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 41164185 (39M) [application/octet-stream]\n",
            "Saving to: â€˜cloudflaredâ€™\n",
            "\n",
            "cloudflared         100%[===================>]  39.26M   222MB/s    in 0.2s    \n",
            "\n",
            "2025-06-28 16:20:47 (222 MB/s) - â€˜cloudflaredâ€™ saved [41164185/41164185]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ! huggingface-cli login"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AMbOngE3Up5X",
        "outputId": "3f35c4f0-a72a-4c3c-e95d-32de4ceda7a9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    To log in, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Enter your token (input will not be visible): \n",
            "Add token as git credential? (Y/n) n\n",
            "Token is valid (permission: write).\n",
            "The token `QA-dataset` has been saved to /root/.cache/huggingface/stored_tokens\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful.\n",
            "The current active token is: `QA-dataset`\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run app.py &> logs.txt &\n",
        "!./cloudflared tunnel --url http://localhost:8501"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KqrREX7sTza_",
        "outputId": "8ec93c55-178b-44b1-d1de-fcde038736a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[90m2025-06-28T16:21:25Z\u001b[0m \u001b[32mINF\u001b[0m Thank you for trying Cloudflare Tunnel. Doing so, without a Cloudflare account, is a quick way to experiment and try it out. However, be aware that these account-less Tunnels have no uptime guarantee, are subject to the Cloudflare Online Services Terms of Use (https://www.cloudflare.com/website-terms/), and Cloudflare reserves the right to investigate your use of Tunnels for violations of such terms. If you intend to use Tunnels in production you should use a pre-created named tunnel by following: https://developers.cloudflare.com/cloudflare-one/connections/connect-apps\n",
            "\u001b[90m2025-06-28T16:21:25Z\u001b[0m \u001b[32mINF\u001b[0m Requesting new quick Tunnel on trycloudflare.com...\n",
            "\u001b[90m2025-06-28T16:21:28Z\u001b[0m \u001b[32mINF\u001b[0m +--------------------------------------------------------------------------------------------+\n",
            "\u001b[90m2025-06-28T16:21:28Z\u001b[0m \u001b[32mINF\u001b[0m |  Your quick Tunnel has been created! Visit it at (it may take some time to be reachable):  |\n",
            "\u001b[90m2025-06-28T16:21:28Z\u001b[0m \u001b[32mINF\u001b[0m |  https://permit-cons-luck-behaviour.trycloudflare.com                                      |\n",
            "\u001b[90m2025-06-28T16:21:28Z\u001b[0m \u001b[32mINF\u001b[0m +--------------------------------------------------------------------------------------------+\n",
            "\u001b[90m2025-06-28T16:21:28Z\u001b[0m \u001b[32mINF\u001b[0m Cannot determine default configuration path. No file [config.yml config.yaml] in [~/.cloudflared ~/.cloudflare-warp ~/cloudflare-warp /etc/cloudflared /usr/local/etc/cloudflared]\n",
            "\u001b[90m2025-06-28T16:21:28Z\u001b[0m \u001b[32mINF\u001b[0m Version 2025.6.1 (Checksum 103ff020ffcc4ad6b542948b95ecff417150c70a17bff3a39ac2670b4159c9bb)\n",
            "\u001b[90m2025-06-28T16:21:28Z\u001b[0m \u001b[32mINF\u001b[0m GOOS: linux, GOVersion: go1.24.2, GoArch: amd64\n",
            "\u001b[90m2025-06-28T16:21:28Z\u001b[0m \u001b[32mINF\u001b[0m Settings: map[ha-connections:1 protocol:quic url:http://localhost:8501]\n",
            "\u001b[90m2025-06-28T16:21:28Z\u001b[0m \u001b[32mINF\u001b[0m cloudflared will not automatically update when run from the shell. To enable auto-updates, run cloudflared as a service: https://developers.cloudflare.com/cloudflare-one/connections/connect-apps/configure-tunnels/local-management/as-a-service/\n",
            "\u001b[90m2025-06-28T16:21:28Z\u001b[0m \u001b[32mINF\u001b[0m Generated Connector ID: 0da9ac4d-7f6c-448c-91cd-24092932095b\n",
            "\u001b[90m2025-06-28T16:21:28Z\u001b[0m \u001b[32mINF\u001b[0m Initial protocol quic\n",
            "\u001b[90m2025-06-28T16:21:28Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use 172.28.0.12 as source for IPv4\n",
            "\u001b[90m2025-06-28T16:21:28Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use :: as source for IPv6\n",
            "\u001b[90m2025-06-28T16:21:28Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use 172.28.0.12 as source for IPv4\n",
            "\u001b[90m2025-06-28T16:21:28Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use :: as source for IPv6\n",
            "\u001b[90m2025-06-28T16:21:28Z\u001b[0m \u001b[32mINF\u001b[0m Starting metrics server on 127.0.0.1:20241/metrics\n",
            "\u001b[90m2025-06-28T16:21:28Z\u001b[0m \u001b[32mINF\u001b[0m Tunnel connection curve preferences: [X25519MLKEM768 CurveID(25497) CurveP256] \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.192.37\n",
            "2025/06/28 16:21:28 failed to sufficiently increase receive buffer size (was: 208 kiB, wanted: 7168 kiB, got: 416 kiB). See https://github.com/quic-go/quic-go/wiki/UDP-Buffer-Sizes for details.\n",
            "\u001b[90m2025-06-28T16:21:28Z\u001b[0m \u001b[32mINF\u001b[0m Registered tunnel connection \u001b[36mconnIndex=\u001b[0m0 \u001b[36mconnection=\u001b[0m2ae09ddf-2033-4783-b557-d29457835905 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.192.37 \u001b[36mlocation=\u001b[0mlax08 \u001b[36mprotocol=\u001b[0mquic\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U2pFGmGzT2-j"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}